{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pdb\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_deploy = 'deploy_SE.prototxt'    # old network deploy file\n",
    "last_model = 'googlenet_SE.caffemodel'    # model parameters to be pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "model_def = last_deploy\n",
    "model_weights = last_model\n",
    "mu = np.load('train_mean_global.npy')\n",
    "mu = mu.mean(1).mean(1)\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "picture_num = 1\n",
    "positive_count = 0\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data',mu)\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "net.blobs['data'].reshape(picture_num,\n",
    "                                  3,\n",
    "                                  224, 224)\n",
    "\n",
    "layers_dict ={}    # save the channel weights of all convolutional layers.\n",
    "layers_list = []\n",
    "for layer_name, blob in net.blobs.iteritems():\n",
    "    if 'up' in layer_name:\n",
    "        print(layer_name)\n",
    "        layers_list.append(layer_name)\n",
    "        layers_dict[layer_name] = np.zeros(blob.data.size/10)\n",
    "        print(blob.data.size/10)\n",
    "\n",
    "image_file = 'train.txt'\n",
    "train_num = 0\n",
    "with open(image_file, 'r') as image_list:\n",
    "    for image in image_list:\n",
    "        image_source = image.strip().split(' ')[0]\n",
    "        label = int(image.strip().split(' ')[1])\n",
    "        image = caffe.io.load_image(image_source)\n",
    "        transformed_image = transformer.preprocess('data',image)\n",
    "        net.blobs['data'].data[0] = transformed_image\n",
    "        output = net.forward()\n",
    "        for layer_name, blob in net.blobs.iteritems():\n",
    "            if 'up' in layer_name:\n",
    "                layers_dict[layer_name] = layers_dict[layer_name] + blob.data[0,:,0,0]    # the scale factors saved in layers named \"xxx_up\".\n",
    "        print(image_source + 'processed.')\n",
    "        train_num = train_num + 1\n",
    "print('Done.')\n",
    "for layer_name in layers_list:\n",
    "    layers_dict[layer_name] = layers_dict[layer_name]/train_num    # compute the channel weights, use mean of all the scale factors we collected when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in layers_list:\n",
    "    plt.figure(layer_name)\n",
    "    plt.ylabel(layer_name)\n",
    "    plt.ylim(0.0,1.0,10)\n",
    "    yticks = np.linspace(0.00,1.00,11)\n",
    "    plt.yticks(yticks)\n",
    "    plt.plot(layers_dict[layer_name])\n",
    "    \n",
    "c_rate = 0.5    # prune rate. If you want to set how many channels to prune directly, you can set this value. For example, 0.5 means prune 50% channels in a convolutionnal layer.\n",
    "#k = 0.1    # k in our paper. If you want to dynamically control how many channels to prune automatically, use this.\n",
    "sorted_layers_dict = {}\n",
    "for layer_name in layers_list:\n",
    "    sorted_layers_dict[layer_name] = sorted(layers_dict[layer_name])\n",
    "    \n",
    "threshold_dict = {}    # save the prune threshold of each convolutional layer.\n",
    "for layer in layers_list:\n",
    "    #threshold_dict[layer] = np.mean(layers_dict[layer])-(k-np.std(layers_dict[layer]))    # dynamically compute the prune threshold.\n",
    "    threshold_dict[layer] = sorted_layers_dict[layer][int(len(sorted_layers_dict[layer])*c_rate)]    # directly use prune rate to compute the prune threshold.\n",
    "threshold_dict\n",
    "\n",
    "channels = {}    # This contains the channels whose channel weight is larger than the threshold, so we can compute the number of channels after pruning and use the remaining channel parameters for next train.\n",
    "for layer in layers_list:\n",
    "    channels[layer] = np.where(layers_dict[layer]>threshold_dict[layer])[0]\n",
    "    print layers_dict[layer].size,channels[layer].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can get your new network structure after pruning because you have known how many channels in each convolutional layer.\n",
    "# And you can get remaining model parameters after pruning because you have known which channels are pruned and which remained.\n",
    "# Finally, you should train the network pruned using the remaining model parameters to make up for the loss of precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
